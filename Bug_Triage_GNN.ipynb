{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwCRt/Zi54anNq/q29Z+2T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashiPi/GNN-Bug-Triage-Assistant/blob/main/Bug_Triage_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyGithub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAyVSw7807sP",
        "outputId": "999f6101-a973-41f2-b1cb-55c1121a3b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyGithub\n",
            "  Downloading pygithub-2.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading pynacl-1.6.1-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (2.32.4)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from PyGithub) (2.5.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pynacl>=1.4.0->PyGithub) (2.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.14.0->PyGithub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.14.0->PyGithub) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.14.0->PyGithub) (2025.10.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->pynacl>=1.4.0->PyGithub) (2.23)\n",
            "Downloading pygithub-2.8.1-py3-none-any.whl (432 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m432.7/432.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynacl-1.6.1-cp38-abi3-manylinux_2_34_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynacl, PyGithub\n",
            "Successfully installed PyGithub-2.8.1 pynacl-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from github import Github\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"Libraries installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfbe9SSS1neA",
        "outputId": "3f024437-5e6c-40cf-89d9-d5a3788377ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_PAT')\n",
        "    print(\"Successfully fetched GITHUB_PAT secret.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Secret 'GITHUB_PAT' not found.\")\n",
        "    print(\"Please add it using the 'key' icon (üîë) on the left panel.\")\n",
        "    raise\n",
        "\n",
        "if not GITHUB_TOKEN:\n",
        "    raise ValueError(\"GitHub PAT is empty. Please check your Colab Secret.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6o9MlFe1sEZ",
        "outputId": "c96cd52d-6e5b-4b97-9e65-bd72ce9ed646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully fetched GITHUB_PAT secret.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = Github(GITHUB_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb68rjgh1z6_",
        "outputId": "1469c751-12fd-453b-8dd9-a105cb89f357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1333792976.py:1: DeprecationWarning: Argument login_or_token is deprecated, please use auth=github.Auth.Token(...) instead\n",
            "  g = Github(GITHUB_TOKEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_NAME = \"microsoft/vscode\"\n",
        "print(f\"Connecting to repository: {REPO_NAME}\")\n",
        "\n",
        "try:\n",
        "    repo = g.get_repo(REPO_NAME)\n",
        "except Exception as e:\n",
        "    print(f\"Error accessing repository: {e}\")\n",
        "    # This often happens if the token is invalid or doesn't have 'public_repo' scope\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Pcs0Ms16I-",
        "outputId": "606906ef-c60b-40f4-d98a-6378232c507c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to repository: microsoft/vscode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fetching closed bug issues...\")\n",
        "\n",
        "output_filename = 'bugs.csv'\n",
        "\n",
        "with open(output_filename, 'w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"bug_id\", \"title\", \"reporter_username\", \"fixer_username\"])\n",
        "\n",
        "    # Get issues labeled 'bug' that are 'closed'\n",
        "    issues = repo.get_issues(\n",
        "        state='closed',\n",
        "        labels=[repo.get_label(\"bug\")]\n",
        "    )\n",
        "\n",
        "    # --- Limit for testing ---\n",
        "    # 100 valid bugs to start.\n",
        "    count = 0\n",
        "    total_checked = 0\n",
        "    BUG_LIMIT = 100\n",
        "\n",
        "    for issue in issues:\n",
        "        total_checked += 1\n",
        "\n",
        "        # We only want bugs that were *fixed* (closed by a user)\n",
        "        if issue.closed_by:\n",
        "            bug_id = issue.number\n",
        "            title = issue.title\n",
        "            reporter_username = issue.user.login\n",
        "            fixer_username = issue.closed_by.login\n",
        "\n",
        "            # Write data to our CSV\n",
        "            writer.writerow([bug_id, title, reporter_username, fixer_username])\n",
        "            count += 1\n",
        "\n",
        "            if count % 20 == 0:\n",
        "                print(f\"  Processed {total_checked} issues... Found {count} valid bugs...\")\n",
        "\n",
        "        if count >= BUG_LIMIT:\n",
        "            print(f\"Reached test limit of {BUG_LIMIT} bugs.\")\n",
        "            break\n",
        "\n",
        "        # To avoid hitting rate limits too fast even when iterating\n",
        "        if total_checked > BUG_LIMIT * 10:\n",
        "             print(f\"Checked {total_checked} issues without finding {BUG_LIMIT} bugs. Stopping to be safe.\")\n",
        "             break\n",
        "\n",
        "print(f\"Successfully created {output_filename} with {count} entries.\")\n",
        "print(f\"You can see the file in the Colab 'Files' tab (folder icon üìÅ) on the left.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpqRxkvu2qdz",
        "outputId": "852b2bec-61aa-4990-fb28-053cefbd150a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching closed bug issues...\n",
            "  Processed 20 issues... Found 20 valid bugs...\n",
            "  Processed 40 issues... Found 40 valid bugs...\n",
            "  Processed 60 issues... Found 60 valid bugs...\n",
            "  Processed 80 issues... Found 80 valid bugs...\n",
            "  Processed 100 issues... Found 100 valid bugs...\n",
            "Reached test limit of 100 bugs.\n",
            "Successfully created bugs.csv with 100 entries.\n",
            "You can see the file in the Colab 'Files' tab (folder icon üìÅ) on the left.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have the bugs.csv file <br>\n",
        "\n",
        "The next, most important step is to find out which files were changed to fix each bug. This will build the core of our graph, connecting Bugs -> Files <- Developers."
      ],
      "metadata": {
        "id": "GvG2O6D3PTVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from github import Github\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "print(\"--- Script 2: Link-Finder ---\")\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_PAT')\n",
        "    print(\"Successfully fetched GITHUB_PAT secret.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Secret 'GITHUB_PAT' not found. Please add it.\")\n",
        "    raise\n",
        "\n",
        "g = Github(GITHUB_TOKEN, retry=5, timeout=15)\n",
        "REPO_NAME = \"microsoft/vscode\"\n",
        "print(f\"Connecting to repository: {REPO_NAME}\")\n",
        "try:\n",
        "    repo = g.get_repo(REPO_NAME)\n",
        "except Exception as e:\n",
        "    print(f\"Error accessing repository: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSXfxReU2tqA",
        "outputId": "73369b2f-1298-4d44-d144-090cba36ad69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Script 2: Link-Finder ---\n",
            "Successfully fetched GITHUB_PAT secret.\n",
            "Connecting to repository: microsoft/vscode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2712398434.py:16: DeprecationWarning: Argument login_or_token is deprecated, please use auth=github.Auth.Token(...) instead\n",
            "  g = Github(GITHUB_TOKEN, retry=5, timeout=15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bug_files_csv = 'bug_to_files.csv'\n",
        "dev_files_csv = 'dev_to_files.csv'\n",
        "\n",
        "all_files = set()\n",
        "\n",
        "with open('bugs.csv', 'r', encoding='utf-8') as f_bugs, \\\n",
        "     open(bug_files_csv, 'w', newline='', encoding='utf-8') as f_bug_files, \\\n",
        "     open(dev_files_csv, 'w', newline='', encoding='utf-8') as f_dev_files:\n",
        "\n",
        "    bug_reader = csv.DictReader(f_bugs)\n",
        "    bug_files_writer = csv.writer(f_bug_files)\n",
        "    dev_files_writer = csv.writer(f_dev_files)\n",
        "\n",
        "    bug_files_writer.writerow([\"bug_id\", \"filepath\"])\n",
        "    dev_files_writer.writerow([\"developer_username\", \"filepath\"])\n",
        "\n",
        "    print(\"Starting to process bugs from bugs.csv...\")\n",
        "\n",
        "    processed_count = 0\n",
        "    total_bugs = 0\n",
        "    for row in bug_reader:\n",
        "        bug_id = row['bug_id']\n",
        "        fixer = row['fixer_username']\n",
        "        total_bugs += 1\n",
        "\n",
        "        query = f\"repo:{REPO_NAME} {bug_id} is:pr is:merged\"\n",
        "\n",
        "        try:\n",
        "            time.sleep(1)\n",
        "\n",
        "            search_results = g.search_issues(query, sort = 'updated')\n",
        "\n",
        "            if search_results.totalCount > 0:\n",
        "                pr_summary = search_results[0]\n",
        "\n",
        "                pr = repo.get_pull(pr_summary.number)\n",
        "\n",
        "                pr_author = pr.user.login\n",
        "                pr_merger = pr.merged_by.login if pr.merged_by else \"\"\n",
        "\n",
        "                pr_files = pr.get_files()\n",
        "\n",
        "                found_files = False\n",
        "                for file in pr_files:\n",
        "                    filepath = file.filename\n",
        "\n",
        "                    bug_files_writer.writerow([bug_id, filepath])\n",
        "                    dev_files_writer.writerow([fixer, filepath])\n",
        "\n",
        "                    all_files.add(filepath)\n",
        "                    found_files = True\n",
        "\n",
        "                if found_files:\n",
        "                    print(f\"  Processed bug #{bug_id}: Found PR #{pr.number} (author: {pr_author}) with {pr_files.totalCount} files.\")\n",
        "                    processed_count += 1\n",
        "                else:\n",
        "                    print(f\"  Processed bug #{bug_id}: Found PR #{pr.number}, but it had 0 files. Skipping.\")\n",
        "\n",
        "            else:\n",
        "                print(f\"  Processed bug #{bug_id}: No merged PR found that 'mentions' it. Skipping.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ERROR processing bug #{bug_id}: {e}\")\n",
        "\n",
        "            if \"API rate limit exceeded\" in str(e):\n",
        "                print(\"!!! RATE LIMIT HIT. Sleeping for 60 seconds... !!!\")\n",
        "                time.sleep(60)\n",
        "\n",
        "    print(f\"\\n--- Process Complete ---\")\n",
        "    print(f\"Processed {total_bugs} bugs from csv.\")\n",
        "    print(f\"Found PRs and files for {processed_count} bugs.\")\n",
        "    print(f\"Created {bug_files_csv} and {dev_files_csv}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYAGyXEuQMXR",
        "outputId": "f44e8bd4-e429-4d38-b848-5118f7dccb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to process bugs from bugs.csv...\n",
            "  Processed bug #276573: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #276548: Found PR #276552 (author: roblourens) with 1 files.\n",
            "  Processed bug #276407: Found PR #276409 (author: JeffreyCA) with 4 files.\n",
            "  Processed bug #276406: Found PR #276409 (author: JeffreyCA) with 4 files.\n",
            "  Processed bug #276305: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #276253: Found PR #276517 (author: Tyriar) with 1 files.\n",
            "  Processed bug #276246: Found PR #276278 (author: bpasero) with 1 files.\n",
            "  Processed bug #276169: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #276167: Found PR #276194 (author: mjbvz) with 1 files.\n",
            "  Processed bug #276165: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #276132: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #276119: Found PR #276118 (author: lszomoru) with 1 files.\n",
            "  Processed bug #276058: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #276035: Found PR #276052 (author: jrieken) with 1 files.\n",
            "  Processed bug #276029: Found PR #276138 (author: connor4312) with 1 files.\n",
            "  Processed bug #275957: Found PR #275972 (author: mjbvz) with 4 files.\n",
            "  Processed bug #275937: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275889: Found PR #275909 (author: Tyriar) with 1 files.\n",
            "  Processed bug #275859: Found PR #276521 (author: jrieken) with 2 files.\n",
            "  Processed bug #275828: Found PR #275836 (author: Tyriar) with 5 files.\n",
            "  Processed bug #275818: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275810: Found PR #275923 (author: bhavyaus) with 1 files.\n",
            "  Processed bug #275789: Found PR #276179 (author: meganrogge) with 6 files.\n",
            "  Processed bug #275723: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #276458: Found PR #276464 (author: alexr00) with 1 files.\n",
            "  Processed bug #275692: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275690: Found PR #275693 (author: meganrogge) with 2 files.\n",
            "  Processed bug #275682: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275675: Found PR #275870 (author: connor4312) with 2 files.\n",
            "  Processed bug #275674: Found PR #275759 (author: sandy081) with 1 files.\n",
            "  Processed bug #275673: Found PR #275410 (author: TylerLeonhardt) with 4 files.\n",
            "  Processed bug #275667: Found PR #275782 (author: Tyriar) with 5 files.\n",
            "  Processed bug #275651: Found PR #275681 (author: meganrogge) with 1 files.\n",
            "  Processed bug #275641: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275631: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275624: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275614: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275605: Found PR #276554 (author: meganrogge) with 2 files.\n",
            "  Processed bug #275592: Found PR #275706 (author: meganrogge) with 2 files.\n",
            "  Processed bug #275578: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275557: Found PR #275577 (author: Copilot) with 3 files.\n",
            "  Processed bug #275556: Found PR #275577 (author: Copilot) with 3 files.\n",
            "  Processed bug #275555: Found PR #275588 (author: meganrogge) with 1 files.\n",
            "  Processed bug #275549: Found PR #275577 (author: Copilot) with 3 files.\n",
            "  Processed bug #275548: Found PR #275577 (author: Copilot) with 3 files.\n",
            "  Processed bug #275546: Found PR #275585 (author: meganrogge) with 1 files.\n",
            "  Processed bug #275521: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275511: Found PR #275910 (author: lramos15) with 4 files.\n",
            "  Processed bug #275478: Found PR #276022 (author: sandy081) with 2 files.\n",
            "  Processed bug #275460: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275443: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275440: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275437: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275435: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275424: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275399: No merged PR found that 'mentions' it. Skipping.\n",
            "  ERROR processing bug #275394: 403 {\"message\": \"API rate limit exceeded for user ID 123788642. If you reach out to GitHub Support for help, please include the request ID 8078:11D5BC:A4BC8F:2E19B24:69134E0D and timestamp 2025-11-11 14:54:06 UTC. For more on scraping GitHub and how it may affect your rights, please review our Terms of Service (https://docs.github.com/en/site-policy/github-terms/github-terms-of-service)\", \"documentation_url\": \"https://docs.github.com/rest/overview/rate-limits-for-the-rest-api\", \"status\": \"403\"}\n",
            "!!! RATE LIMIT HIT. Sleeping for 60 seconds... !!!\n",
            "  Processed bug #275388: Found PR #275878 (author: meganrogge) with 1 files.\n",
            "  Processed bug #275385: Found PR #275582 (author: meganrogge) with 2 files.\n",
            "  Processed bug #275382: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275363: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275361: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275351: Found PR #275590 (author: Tyriar) with 1 files.\n",
            "  Processed bug #275340: Found PR #275531 (author: sandy081) with 1 files.\n",
            "  Processed bug #275337: Found PR #275526 (author: Copilot) with 1 files.\n",
            "  Processed bug #275335: Found PR #275583 (author: Tyriar) with 1 files.\n",
            "  Processed bug #275330: Found PR #275419 (author: benvillalobos) with 2 files.\n",
            "  Processed bug #275326: Found PR #275419 (author: benvillalobos) with 2 files.\n",
            "  Processed bug #275323: Found PR #275712 (author: osortega) with 1 files.\n",
            "  Processed bug #275321: Found PR #275416 (author: dmitrivMS) with 3 files.\n",
            "  Processed bug #275320: Found PR #275790 (author: bpasero) with 1 files.\n",
            "  Processed bug #275304: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275279: Found PR #275308 (author: Copilot) with 1 files.\n",
            "  Processed bug #275264: Found PR #275273 (author: meganrogge) with 2 files.\n",
            "  Processed bug #275258: Found PR #275703 (author: benvillalobos) with 1 files.\n",
            "  Processed bug #275250: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275245: Found PR #275803 (author: bpasero) with 5 files.\n",
            "  Processed bug #275240: Found PR #275833 (author: bpasero) with 1 files.\n",
            "  Processed bug #275237: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275233: Found PR #275892 (author: connor4312) with 3 files.\n",
            "  Processed bug #275227: Found PR #275426 (author: connor4312) with 1 files.\n",
            "  Processed bug #275226: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275214: Found PR #275580 (author: jrieken) with 2 files.\n",
            "  Processed bug #275211: Found PR #275778 (author: Copilot) with 1 files.\n",
            "  Processed bug #275208: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275199: Found PR #275813 (author: aeschli) with 2 files.\n",
            "  Processed bug #275179: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275177: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275173: Found PR #275512 (author: jrieken) with 1 files.\n",
            "  Processed bug #275160: Found PR #275629 (author: sandy081) with 1 files.\n",
            "  Processed bug #275162: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275141: Found PR #275369 (author: meganrogge) with 1 files.\n",
            "  ERROR processing bug #275140: 403 {\"message\": \"API rate limit exceeded for user ID 123788642. If you reach out to GitHub Support for help, please include the request ID A5AA:FD656:15361FF3:601A762D:69134EC2 and timestamp 2025-11-11 14:57:06 UTC. For more on scraping GitHub and how it may affect your rights, please review our Terms of Service (https://docs.github.com/en/site-policy/github-terms/github-terms-of-service)\", \"documentation_url\": \"https://docs.github.com/rest/overview/rate-limits-for-the-rest-api\", \"status\": \"403\"}\n",
            "!!! RATE LIMIT HIT. Sleeping for 60 seconds... !!!\n",
            "  Processed bug #275135: Found PR #275581 (author: lszomoru) with 1 files.\n",
            "  Processed bug #275752: No merged PR found that 'mentions' it. Skipping.\n",
            "  Processed bug #275115: Found PR #276492 (author: Tyriar) with 1 files.\n",
            "  Processed bug #275110: Found PR #275619 (author: amunger) with 1 files.\n",
            "  Processed bug #275099: Found PR #275564 (author: sandy081) with 4 files.\n",
            "  Processed bug #275092: Found PR #275536 (author: sandy081) with 1 files.\n",
            "  Processed bug #275089: Found PR #275145 (author: lszomoru) with 1 files.\n",
            "\n",
            "--- Process Complete ---\n",
            "Processed 100 bugs from csv.\n",
            "Found PRs and files for 62 bugs.\n",
            "Created bug_to_files.csv and dev_to_files.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_csv = 'files.csv'\n",
        "with open(files_csv, 'w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"file_id\", \"filepath\"])\n",
        "\n",
        "    for i, filepath in enumerate(all_files):\n",
        "        writer.writerow([i, filepath])\n",
        "\n",
        "print(f\"Created {files_csv} with {len(all_files)} unique filepaths.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OetoMEBJQbmv",
        "outputId": "d45a5131-ebb0-43d5-f9e7-29d0f1620e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created files.csv with 92 unique filepaths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2: Graph Construction & Feature Engineering"
      ],
      "metadata": {
        "id": "T_9eKcKpfOpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch\n",
        "!pip install torch -q"
      ],
      "metadata": {
        "id": "wn6V8O0ZfOQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "TORCH_VERSION = torch.__version__\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-{TORCH_VERSION}.html -q\n",
        "\n",
        "!pip install sentence-transformers -q\n",
        "\n",
        "print(\"All ML libraries installed successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0cPx5VOfdgV",
        "outputId": "777440e6-5763-4dcb-abaf-c36f56745e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hAll ML libraries installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(\"--- Phase 2: Graph Builder & Feature Engineering ---\")\n",
        "\n",
        "try:\n",
        "    bugs_df = pd.read_csv('bugs.csv')\n",
        "    files_df = pd.read_csv('files.csv')\n",
        "    bug_files_df = pd.read_csv('bug_to_files.csv')\n",
        "    dev_files_df = pd.read_csv('dev_to_files.csv')\n",
        "    print(\"Successfully loaded all 4 CSV files.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}. Make sure all CSV files are in the Colab environment.\")\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beuWVan3f1g2",
        "outputId": "e6b53ab2-de4a-46c2-8a6d-184d01fe2a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Phase 2: Graph Builder & Feature Engineering ---\n",
            "Successfully loaded all 4 CSV files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_df = files_df.sort_values(by='file_id').set_index('file_id')\n",
        "file_path_to_id = {row['filepath']: index for index, row in files_df.iterrows()}\n",
        "num_files = len(files_df)\n",
        "print(f\"Mapped {num_files} files.\")\n",
        "\n",
        "unique_devs = set(bugs_df['fixer_username']).union(set(dev_files_df['developer_username']))\n",
        "dev_to_id = {name: i for i, name in enumerate(unique_devs)}\n",
        "num_devs = len(dev_to_id)\n",
        "print(f\"Mapped {num_devs} unique developers.\")\n",
        "\n",
        "bugs_with_files = set(bug_files_df['bug_id'])\n",
        "bugs_df = bugs_df[bugs_df['bug_id'].isin(bugs_with_files)]\n",
        "bug_id_to_node_idx = {bug_id: i for i, bug_id in enumerate(bugs_df['bug_id'])}\n",
        "num_bugs = len(bug_id_to_node_idx)\n",
        "print(f\"Mapped {num_bugs} bugs (that have file connections).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf0J28oqgp5b",
        "outputId": "3f954442-1ffc-4e4f-e6b3-e87afd81a328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped 92 files.\n",
            "Mapped 26 unique developers.\n",
            "Mapped 62 bugs (that have file connections).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting feature engineering...\")\n",
        "\n",
        "# (A) Bug Features: Use Sentence Transformer on bug titles\n",
        "# This model is small, fast, and very effective\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"  Loaded SentenceTransformer model.\")\n",
        "\n",
        "# Get bug titles in the correct order\n",
        "bug_titles = [bugs_df[bugs_df['bug_id'] == bug_id].iloc[0]['title'] for bug_id in bug_id_to_node_idx.keys()]\n",
        "\n",
        "# Create embeddings.\n",
        "with torch.no_grad():\n",
        "    bug_features = model.encode(bug_titles, convert_to_tensor=True, show_progress_bar=True)\n",
        "bug_features = bug_features.to(torch.float)\n",
        "print(f\"  Created bug features tensor with shape: {bug_features.shape}\")\n",
        "\n",
        "# (B) Developer Features: Simple identity matrix (one-hot)\n",
        "# The GNN will learn features based on connections\n",
        "dev_features = torch.eye(num_devs, dtype=torch.float)\n",
        "print(f\"  Created developer features tensor with shape: {dev_features.shape}\")\n",
        "\n",
        "# (C) File Features: Simple identity matrix\n",
        "file_features = torch.eye(num_files, dtype=torch.float)\n",
        "print(f\"  Created file features tensor with shape: {file_features.shape}\")\n"
      ],
      "metadata": {
        "id": "RkFgcvTShaSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building HeteroData object...\")\n",
        "data = HeteroData()\n",
        "\n",
        "data['bug'].x = bug_features\n",
        "data['developer'].x = dev_features\n",
        "data['file'].x = file_features\n",
        "\n",
        "# (A) Edge: (Bug) - 'mentions' -> (File)\n",
        "# We need to map the CSV rows to our new integer IDs\n",
        "bug_indices = []\n",
        "file_indices_for_bugs = []\n",
        "for _, row in bug_files_df.iterrows():\n",
        "    if row['bug_id'] in bug_id_to_node_idx and row['filepath'] in file_path_to_id:\n",
        "        bug_indices.append(bug_id_to_node_idx[row['bug_id']])\n",
        "        file_indices_for_bugs.append(file_path_to_id[row['filepath']])\n",
        "\n",
        "bug_file_edge_index = torch.tensor([bug_indices, file_indices_for_bugs], dtype=torch.long)\n",
        "data['bug', 'mentions', 'file'].edge_index = bug_file_edge_index\n",
        "print(f\"  Added {bug_file_edge_index.shape[1]} 'mentions' edges.\")\n",
        "\n",
        "\n",
        "# (B) Edge: (Developer) - 'modified' -> (File)\n",
        "dev_indices = []\n",
        "file_indices_for_devs = []\n",
        "for _, row in dev_files_df.iterrows():\n",
        "    if row['developer_username'] in dev_to_id and row['filepath'] in file_path_to_id:\n",
        "        dev_indices.append(dev_to_id[row['developer_username']])\n",
        "        file_indices_for_devs.append(file_path_to_id[row['filepath']])\n",
        "\n",
        "dev_file_edge_index = torch.tensor([dev_indices, file_indices_for_devs], dtype=torch.long)\n",
        "data['developer', 'modified', 'file'].edge_index = dev_file_edge_index\n",
        "print(f\"  Added {dev_file_edge_index.shape[1]} 'modified' edges.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yON08KS7hq_j",
        "outputId": "06da9516-2df6-437d-f862-b262942f12e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building HeteroData object...\n",
            "  Added 121 'mentions' edges.\n",
            "  Added 121 'modified' edges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is our target: the (Developer, Bug) pair we want to predict\n",
        "fixer_indices = []\n",
        "bug_indices_for_fixer = []\n",
        "for _, row in bugs_df.iterrows():\n",
        "    if row['fixer_username'] in dev_to_id:\n",
        "        fixer_indices.append(dev_to_id[row['fixer_username']])\n",
        "        bug_indices_for_fixer.append(bug_id_to_node_idx[row['bug_id']])\n",
        "\n",
        "data['developer', 'fixes', 'bug'].edge_label_index = torch.tensor([fixer_indices, bug_indices_for_fixer], dtype=torch.long)\n",
        "print(f\"  Added {len(fixer_indices)} 'fixes' edges as our ground truth.\")\n",
        "\n",
        "print(\"\\n--- Graph Construction Complete! ---\")\n",
        "print(f\"\\nFinal HeteroData object:\\n{data}\")\n",
        "print(\"\\nThis object 'data' now holds our entire graph.\")\n",
        "\n",
        "torch.save(data, 'graph_data.pt')\n",
        "print(\"\\nGraph data saved to 'graph_data.pt'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4mCbYPFh2AC",
        "outputId": "4c9c8829-c80b-4534-a068-da482f9ce2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Added 62 'fixes' edges as our ground truth.\n",
            "\n",
            "--- Graph Construction Complete! ---\n",
            "\n",
            "Final HeteroData object:\n",
            "HeteroData(\n",
            "  bug={ x=[62, 384] },\n",
            "  developer={ x=[26, 26] },\n",
            "  file={ x=[92, 92] },\n",
            "  (bug, mentions, file)={ edge_index=[2, 121] },\n",
            "  (developer, modified, file)={ edge_index=[2, 121] },\n",
            "  (developer, fixes, bug)={ edge_label_index=[2, 62] }\n",
            ")\n",
            "\n",
            "This object 'data' now holds our entire graph.\n",
            "\n",
            "Graph data saved to 'graph_data.pt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LytvvA-Rh3VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3: Model Building & Training"
      ],
      "metadata": {
        "id": "An4apYpWiY2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"--- Step 1: Loading, Fixing, and Splitting Data (v3) ---\")\n",
        "\n",
        "# Load saved graph\n",
        "data = torch.load('graph_data.pt', weights_only = False)\n",
        "\n",
        "print(\"Applying hotfix 1: Renaming 'edge_label_index' to 'edge_index' for 'fixes'...\")\n",
        "if 'edge_label_index' in data['developer', 'fixes', 'bug']:\n",
        "    data['developer', 'fixes', 'bug'].edge_index = data['developer', 'fixes', 'bug'].edge_label_index\n",
        "    del data['developer', 'fixes', 'bug'].edge_label_index\n",
        "    print(\"Fix 1 applied successfully.\")\n",
        "else:\n",
        "    print(\"Fix 1 already applied.\")\n",
        "\n",
        "\n",
        "# We must ONLY make the MESSAGE PASSING edges bidirectional.\n",
        "# T.ToUndirected() on the whole graph was a mistake as it leaked the answer.\n",
        "# We will add the reverse edges manually to allow message flow.\n",
        "print(\"Applying hotfix 2: Manually reversing message-passing edges...\")\n",
        "\n",
        "edge_index_dev_file = data['developer', 'modified', 'file'].edge_index\n",
        "\n",
        "data['file', 'rev_modified', 'developer'].edge_index = edge_index_dev_file.flip([0])\n",
        "\n",
        "edge_index_bug_file = data['bug', 'mentions', 'file'].edge_index\n",
        "\n",
        "data['file', 'rev_mentions', 'bug'].edge_index = edge_index_bug_file.flip([0])\n",
        "\n",
        "print(\"Fix 2 applied. 'developer' and 'bug' nodes can now be updated.\")\n",
        "\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    is_undirected=False,\n",
        "    add_negative_train_samples=True,\n",
        "    edge_types=[('developer', 'fixes', 'bug')],\n",
        "    rev_edge_types=[('bug', 'rev_fixes', 'developer')],\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = transform(data)\n",
        "\n",
        "print(\"\\n--- Data Splitting Complete ---\")\n",
        "print(f\"Original Data (pre-split, after fixes):\\n{data}\")\n",
        "\n",
        "print(\"\\nTraining Data (what the model sees):\")\n",
        "print(train_data)\n",
        "print(\"\\nValidation Data (for checking):\")\n",
        "print(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fXIr78krWxa",
        "outputId": "84af8817-debb-4dd8-b84a-3b74b3e6c331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Loading, Fixing, and Splitting Data (v3) ---\n",
            "Applying hotfix 1: Renaming 'edge_label_index' to 'edge_index' for 'fixes'...\n",
            "Fix 1 applied successfully.\n",
            "Applying hotfix 2: Manually reversing message-passing edges...\n",
            "Fix 2 applied. 'developer' and 'bug' nodes can now be updated.\n",
            "\n",
            "--- Data Splitting Complete ---\n",
            "Original Data (pre-split, after fixes):\n",
            "HeteroData(\n",
            "  bug={ x=[62, 384] },\n",
            "  developer={ x=[26, 26] },\n",
            "  file={ x=[92, 92] },\n",
            "  (bug, mentions, file)={ edge_index=[2, 121] },\n",
            "  (developer, modified, file)={ edge_index=[2, 121] },\n",
            "  (developer, fixes, bug)={ edge_index=[2, 62] },\n",
            "  (file, rev_modified, developer)={ edge_index=[2, 121] },\n",
            "  (file, rev_mentions, bug)={ edge_index=[2, 121] }\n",
            ")\n",
            "\n",
            "Training Data (what the model sees):\n",
            "HeteroData(\n",
            "  bug={ x=[62, 384] },\n",
            "  developer={ x=[26, 26] },\n",
            "  file={ x=[92, 92] },\n",
            "  (bug, mentions, file)={ edge_index=[2, 121] },\n",
            "  (developer, modified, file)={ edge_index=[2, 121] },\n",
            "  (developer, fixes, bug)={\n",
            "    edge_index=[2, 50],\n",
            "    edge_label=[100],\n",
            "    edge_label_index=[2, 100],\n",
            "  },\n",
            "  (file, rev_modified, developer)={ edge_index=[2, 121] },\n",
            "  (file, rev_mentions, bug)={ edge_index=[2, 121] },\n",
            "  (bug, rev_fixes, developer)={}\n",
            ")\n",
            "\n",
            "Validation Data (for checking):\n",
            "HeteroData(\n",
            "  bug={ x=[62, 384] },\n",
            "  developer={ x=[26, 26] },\n",
            "  file={ x=[92, 92] },\n",
            "  (bug, mentions, file)={ edge_index=[2, 121] },\n",
            "  (developer, modified, file)={ edge_index=[2, 121] },\n",
            "  (developer, fixes, bug)={\n",
            "    edge_index=[2, 50],\n",
            "    edge_label=[12],\n",
            "    edge_label_index=[2, 12],\n",
            "  },\n",
            "  (file, rev_modified, developer)={ edge_index=[2, 121] },\n",
            "  (file, rev_mentions, bug)={ edge_index=[2, 121] },\n",
            "  (bug, rev_fixes, developer)={}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the simple GNN \"blueprint\"\n",
        "# This is a standard 2-layer GraphSAGE model\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, metadata):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, out_channels)\n",
        "\n",
        "        self.encoder = to_hetero(self.encoder, metadata, aggr='sum')\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return z_dict\n",
        "\n",
        "    def decode(self, z_dict, edge_label_index):\n",
        "        dev_emb = z_dict['developer']\n",
        "        bug_emb = z_dict['bug']\n",
        "\n",
        "        src_dev_nodes = edge_label_index[0]\n",
        "        dst_bug_nodes = edge_label_index[1]\n",
        "\n",
        "        dev_src_emb = dev_emb[src_dev_nodes]\n",
        "        bug_dst_emb = bug_emb[dst_bug_nodes]\n",
        "\n",
        "        # --- This is our prediction ---\n",
        "        # We do a simple dot-product.\n",
        "        # If the embeddings are \"similar\", the score will be high.\n",
        "        pred = (dev_src_emb * bug_dst_emb).sum(dim=-1)\n",
        "        return pred\n",
        "\n",
        "print(\"--- Model Definition Complete ---\")\n",
        "\n",
        "print(\"Cleaning metadata for model initialization...\")\n",
        "node_types, edge_types = train_data.metadata()\n",
        "\n",
        "clean_edge_types = []\n",
        "for edge_type in edge_types:\n",
        "    edge_name = edge_type[1]\n",
        "\n",
        "    if 'fixes' not in edge_name:\n",
        "        clean_edge_types.append(edge_type)\n",
        "\n",
        "clean_metadata = (node_types, tuple(clean_edge_types))\n",
        "print(\"Metadata cleaned.\")\n",
        "\n",
        "model = Model(\n",
        "    hidden_channels=64,\n",
        "    out_channels=64,\n",
        "    metadata=clean_metadata\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-PTR4ZnlqES",
        "outputId": "37275ec8-616f-4c77-8802-017adbd35534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Definition Complete ---\n",
            "Cleaning metadata for model initialization...\n",
            "Metadata cleaned.\n",
            "Model(\n",
            "  (encoder): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (bug__mentions__file): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (developer__modified__file): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (file__rev_modified__developer): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (file__rev_mentions__bug): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (bug__mentions__file): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (developer__modified__file): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (file__rev_modified__developer): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (file__rev_mentions__bug): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# We use Binary Cross-Entropy with Logits Loss\n",
        "# This is standard for binary (0/1) prediction\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    z_dict = model.forward(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "    pred = model.decode(z_dict, train_data['developer', 'fixes', 'bug'].edge_label_index)\n",
        "\n",
        "    target = train_data['developer', 'fixes', 'bug'].edge_label.to(torch.float)\n",
        "\n",
        "    loss = loss_fn(pred, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data_to_test):\n",
        "    model.eval()\n",
        "\n",
        "    z_dict = model.forward(data_to_test.x_dict, data_to_test.edge_index_dict)\n",
        "\n",
        "    pred = model.decode(z_dict, data_to_test['developer', 'fixes', 'bug'].edge_label_index)\n",
        "\n",
        "    target = data_to_test['developer', 'fixes', 'bug'].edge_label\n",
        "\n",
        "    pred = pred.cpu().numpy()\n",
        "    target = target.cpu().numpy()\n",
        "\n",
        "    return roc_auc_score(target, pred)\n",
        "\n",
        "print(\"\\n--- Starting Training ---\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        val_auc = test(val_data)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}')\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\n--- Training Complete ---\")\n",
        "print(f\"Total time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "final_test_auc = test(test_data)\n",
        "\n",
        "print(f'\\n==============================')\n",
        "print(f'   Final Test AUC: {final_test_auc:.4f}')\n",
        "print(f'==============================')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy3QnUoulp6p",
        "outputId": "a5893f54-cbca-4c05-d2e4-c6a47af3610e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- Starting Training ---\n",
            "Epoch: 010, Loss: 0.0302, Val AUC: 0.4722\n",
            "Epoch: 020, Loss: 0.0001, Val AUC: 0.5833\n",
            "Epoch: 030, Loss: 0.0000, Val AUC: 0.5833\n",
            "Epoch: 040, Loss: 0.0000, Val AUC: 0.6111\n",
            "Epoch: 050, Loss: 0.0000, Val AUC: 0.6111\n",
            "Epoch: 060, Loss: 0.0000, Val AUC: 0.6111\n",
            "Epoch: 070, Loss: 0.0000, Val AUC: 0.6111\n",
            "Epoch: 080, Loss: 0.0000, Val AUC: 0.6111\n",
            "Epoch: 090, Loss: 0.0000, Val AUC: 0.6111\n",
            "Epoch: 100, Loss: 0.0000, Val AUC: 0.6111\n",
            "\n",
            "--- Training Complete ---\n",
            "Total time: 1.05 seconds\n",
            "\n",
            "==============================\n",
            "   Final Test AUC: 0.8333\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Verifying model keys before saving ---\")\n",
        "\n",
        "keys = model.state_dict().keys()\n",
        "\n",
        "found_bad_keys = False\n",
        "for k in keys:\n",
        "    if \"fixes\" in k:\n",
        "        print(f\"FOUND BAD KEY: {k}\")\n",
        "        found_bad_keys = True\n",
        "\n",
        "if found_bad_keys:\n",
        "    print(\"\\n--- ERROR! ---\")\n",
        "    print(\"Your 'model' object is still the old, bad one. Please restart runtime (Step 1) and try again.\")\n",
        "else:\n",
        "    print(\"\\n--- SUCCESS! ---\")\n",
        "    print(\"Model is correct. No 'fixes' layers found. Saving to file...\")\n",
        "\n",
        "    # Save the model\n",
        "    model_save_path = 'gnn_bug_triage_model.pth'\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "    print(f\"Trained model weights saved to {model_save_path}\")\n",
        "    print(\"You can now download this new file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOtX02e7rqXt",
        "outputId": "a13cd7ba-6c2c-4a36-d09a-ec69a59cfe66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Verifying model keys before saving ---\n",
            "\n",
            "--- SUCCESS! ---\n",
            "Model is correct. No 'fixes' layers found. Saving to file...\n",
            "Trained model weights saved to gnn_bug_triage_model.pth\n",
            "You can now download this new file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "WwzJG4BvdQH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "\n",
        "GRAPH_PATH = \"graph_data.pt\"\n",
        "MODEL_PATH = \"gnn_bug_triage_model.pth\"\n",
        "BUGS_CSV_PATH = \"bugs.csv\"\n",
        "DEV_FILES_CSV_PATH = \"dev_to_files.csv\"\n",
        "\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, metadata):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, out_channels)\n",
        "        self.encoder = to_hetero(self.encoder, metadata, aggr='sum')\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        return self.encoder(x_dict, edge_index_dict)\n",
        "\n",
        "print(\"--- Loading all assets for testing... ---\")\n",
        "\n",
        "device = torch.device('cpu')\n",
        "full_data = torch.load(GRAPH_PATH, weights_only = False)\n",
        "\n",
        "print(\"Adding reverse edges for message passing...\")\n",
        "edge_index_dev_file = full_data['developer', 'modified', 'file'].edge_index\n",
        "full_data['file', 'rev_modified', 'developer'].edge_index = edge_index_dev_file.flip([0])\n",
        "edge_index_bug_file = full_data['bug', 'mentions', 'file'].edge_index\n",
        "full_data['file', 'rev_mentions', 'bug'].edge_index = edge_index_bug_file.flip([0])\n",
        "\n",
        "print(\"Cleaning metadata for model initialization...\")\n",
        "node_types, edge_types = full_data.metadata()\n",
        "clean_edge_types = []\n",
        "for edge_type in edge_types:\n",
        "    if 'fixes' not in edge_type[1]: # Filter out 'fixes' links\n",
        "        clean_edge_types.append(edge_type)\n",
        "clean_metadata = (node_types, tuple(clean_edge_types))\n",
        "full_data = full_data.to(device)\n",
        "\n",
        "print(\"Loading models...\")\n",
        "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "text_model.eval()\n",
        "\n",
        "gnn_model = Model(hidden_channels=64, out_channels=64, metadata=clean_metadata)\n",
        "gnn_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "gnn_model.eval()\n",
        "print(\"Models loaded successfully.\")\n",
        "\n",
        "bugs_df = pd.read_csv(BUGS_CSV_PATH)\n",
        "dev_files_df = pd.read_csv(DEV_FILES_CSV_PATH)\n",
        "unique_devs = set(bugs_df['fixer_username']).union(set(dev_files_df['developer_username']))\n",
        "dev_to_id = {name: i for i, name in enumerate(unique_devs)}\n",
        "id_to_dev = {i: name for name, i in dev_to_id.items()}\n",
        "print(f\"Loaded {len(id_to_dev)} developer mappings.\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_triage(bug_title, bug_body):\n",
        "    print(f\"\\n--- Predicting for: '{bug_title}' ---\")\n",
        "\n",
        "    z_dict = gnn_model.forward(full_data.x_dict, full_data.edge_index_dict)\n",
        "\n",
        "    new_bug_text = bug_title + \" \" + bug_body\n",
        "    new_bug_raw_embedding = text_model.encode(new_bug_text, convert_to_tensor=True).to(device)\n",
        "    new_bug_raw_embedding = new_bug_raw_embedding.to(torch.float)\n",
        "\n",
        "    conv1_bug_layer = gnn_model.encoder.conv1['file__rev_mentions__bug']\n",
        "    conv2_bug_layer = gnn_model.encoder.conv2['file__rev_mentions__bug']\n",
        "\n",
        "    new_bug_h1 = conv1_bug_layer.lin_r(new_bug_raw_embedding).relu()\n",
        "    new_bug_final_embedding = conv2_bug_layer.lin_r(new_bug_h1) # Shape is now [64]\n",
        "\n",
        "    all_dev_embeddings = z_dict['developer'] # Shape [num_devs, 64]\n",
        "\n",
        "    scores = (all_dev_embeddings * new_bug_final_embedding).sum(dim=-1)\n",
        "\n",
        "    scores, top_k_indices = torch.topk(scores, 3)\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(top_k_indices)):\n",
        "        dev_node_id = top_k_indices[i].item()\n",
        "        dev_username = id_to_dev.get(dev_node_id, \"Unknown-Developer\")\n",
        "        score = scores[i].item()\n",
        "        results.append({\"username\": dev_username, \"score\": float(score)})\n",
        "\n",
        "    return results\n",
        "\n",
        "# --- TEST IT! ---\n",
        "recommendations = predict_triage(\n",
        "    \"Search bar is slow\",\n",
        "    \"The main search function is performing poorly.\"\n",
        ")\n",
        "\n",
        "print(\"\\nRECOMMENDATIONS:\")\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiVGm3v9TCAa",
        "outputId": "7b90aa83-f4db-4fbe-dc2f-18330b7c8155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading all assets for testing... ---\n",
            "Adding reverse edges for message passing...\n",
            "Cleaning metadata for model initialization...\n",
            "Loading models...\n",
            "Models loaded successfully.\n",
            "Loaded 26 developer mappings.\n",
            "\n",
            "--- Predicting for: 'Search bar is slow' ---\n",
            "\n",
            "RECOMMENDATIONS:\n",
            "[{'username': 'jrieken', 'score': 1.0952004194259644}, {'username': 'lszomoru', 'score': 0.8538224697113037}, {'username': 'meganrogge', 'score': 0.8496090173721313}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MORE TESTS ---\n",
        "\n",
        "# Test 1: A bug about file management\n",
        "print(\"--- Test Case 1: File Explorer Bug ---\")\n",
        "recommendations_file = predict_triage(\n",
        "    \"Cannot drag and drop file in sidebar\",\n",
        "    \"The file explorer tree view doesn't update when I move a file. It's a rendering issue in the 'explorer' panel.\"\n",
        ")\n",
        "print(\"\\nRECOMMENDATIONS (File Bug):\")\n",
        "print(recommendations_file)\n",
        "\n",
        "# Test 2: A bug about UI/rendering\n",
        "print(\"\\n--- Test Case 2: UI Rendering Bug ---\")\n",
        "recommendations_ui = predict_triage(\n",
        "    \"Dropdown menu renders in wrong place\",\n",
        "    \"The 'select' or 'dropdown' component in the workbench is not displaying correctly. It appears in the top corner of the screen.\"\n",
        ")\n",
        "print(\"\\nRECOMMENDATIONS (UI Bug):\")\n",
        "print(recommendations_ui)\n",
        "\n",
        "# Test 3: A generic bug about performance\n",
        "print(\"\\n--- Test Case 3: Performance Bug ---\")\n",
        "recommendations_perf = predict_triage(\n",
        "    \"App is slow on startup\",\n",
        "    \"VSCode is taking a long time to load. Seems like a main process or 'workbench' loading issue.\"\n",
        ")\n",
        "print(\"\\nRECOMMENDATIONS (Performance Bug):\")\n",
        "print(recommendations_perf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pRflo35l7ox",
        "outputId": "2f80b638-ec3f-4138-d451-1c4af0cbf3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Test Case 1: File Explorer Bug ---\n",
            "\n",
            "--- Predicting for: 'Cannot drag and drop file in sidebar' ---\n",
            "\n",
            "RECOMMENDATIONS (File Bug):\n",
            "[{'username': 'Tyriar', 'score': 4.344862937927246}, {'username': 'meganrogge', 'score': 3.8368003368377686}, {'username': 'jrieken', 'score': 3.7280516624450684}]\n",
            "\n",
            "--- Test Case 2: UI Rendering Bug ---\n",
            "\n",
            "--- Predicting for: 'Dropdown menu renders in wrong place' ---\n",
            "\n",
            "RECOMMENDATIONS (UI Bug):\n",
            "[{'username': 'meganrogge', 'score': 2.5281147956848145}, {'username': 'jrieken', 'score': 2.506861686706543}, {'username': 'lszomoru', 'score': 1.188596248626709}]\n",
            "\n",
            "--- Test Case 3: Performance Bug ---\n",
            "\n",
            "--- Predicting for: 'App is slow on startup' ---\n",
            "\n",
            "RECOMMENDATIONS (Performance Bug):\n",
            "[{'username': 'benvillalobos', 'score': 0.7458015084266663}, {'username': 'jrieken', 'score': 0.7192777991294861}, {'username': 'lszomoru', 'score': 0.46238595247268677}]\n"
          ]
        }
      ]
    }
  ]
}